{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUkPMQLwrqs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Add, MaxPool2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neiHyk2Sr3B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_block(x, kernel_size, filters, layers=2):\n",
        "    shortcut_x = x\n",
        "\n",
        "    for l in range(layers):\n",
        "        x = Conv2D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        if l == layers-1:\n",
        "            if K.int_shape(x) != K.int_shape(shortcut_x):\n",
        "                shortcut_x = Conv2D(filters=filters, kernel_size=(1,1), padding='same')(shortcut_x)\n",
        "\n",
        "            x = Add()([x, shortcut_x])\n",
        "\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK5daQ0ir-HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_shape, blocks, block_sets, kernel_size=(3,3), first_filters=32, block_layers=2):\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # 入力層\n",
        "    x = Conv2D(filters=first_filters, kernel_size=kernel_size, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # 畳み込み層\n",
        "    for s in range(block_sets):\n",
        "        # blockset単位でfilter数を2倍にしていく\n",
        "        filters = first_filters * (2**s)\n",
        "\n",
        "        for b in range(blocks):\n",
        "            x = residual_block(x, kernel_size, filters, block_layers)\n",
        "\n",
        "        x = MaxPool2D((2, 2))(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "    # 出力層\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBhsaCvRsEeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad89bbb2-addc-44bb-c75c-cb6aa2f7c9f1"
      },
      "source": [
        "# データロード\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 0~1に正規化\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "train_samples = x_train.shape[0]\n",
        "test_samples = x_test.shape[0]\n",
        "\n",
        "# ハイパーパラメータ\n",
        "epochs = 200\n",
        "batch_size = 64\n",
        "\n",
        "optimizer=Adam()\n",
        "\n",
        "# resnetモデル\n",
        "model = build_model(input_shape, blocks=3, block_sets=3)\n",
        "model.compile(optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(x_train, y_train, batch_size, epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 32)   0           leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 16, 16, 32)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 32)   9248        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16, 16, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 16, 16, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 32)   9248        leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 16, 16, 32)   0           batch_normalization_2[0][0]      \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 32)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 32)   9248        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 16, 16, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 32)   9248        leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 32)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 32)   9248        leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 32)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 32)     0           leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 8, 8, 32)     0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 8, 8, 64)     18496       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 8, 8, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 64)     36928       leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 64)     256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 64)     2112        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8, 8, 64)     0           batch_normalization_8[0][0]      \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 64)     0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 8, 8, 64)     256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 64)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 8, 8, 64)     256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 64)     0           batch_normalization_10[0][0]     \n",
            "                                                                 leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 64)     0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 64)     256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 64)     256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 64)     0           batch_normalization_12[0][0]     \n",
            "                                                                 leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 8, 8, 64)     0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 64)     0           leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 4, 4, 64)     0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 4, 4, 128)    73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 4, 4, 128)    512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 4, 4, 128)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 4, 4, 128)    147584      leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 4, 4, 128)    512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 128)    8320        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 4, 4, 128)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 128)    147584      leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 4, 4, 128)    512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 4, 4, 128)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 128)    147584      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 4, 4, 128)    512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 128)    0           batch_normalization_16[0][0]     \n",
            "                                                                 leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 4, 4, 128)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 128)    147584      leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 4, 4, 128)    512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 4, 4, 128)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 128)    147584      leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 4, 4, 128)    512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 128)    0           batch_normalization_18[0][0]     \n",
            "                                                                 leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 4, 4, 128)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 128)    0           leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 2, 2, 128)    0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 512)          0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 512)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          51300       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           1010        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,139,542\n",
            "Trainable params: 1,136,790\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 2.0712 - accuracy: 0.2264 - val_loss: 1.8714 - val_accuracy: 0.2876\n",
            "Epoch 2/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 1.5369 - accuracy: 0.4070 - val_loss: 2.6429 - val_accuracy: 0.2995\n",
            "Epoch 3/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 1.3044 - accuracy: 0.5237 - val_loss: 1.2975 - val_accuracy: 0.5392\n",
            "Epoch 4/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 1.1342 - accuracy: 0.5974 - val_loss: 1.0582 - val_accuracy: 0.6278\n",
            "Epoch 5/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 1.0321 - accuracy: 0.6408 - val_loss: 0.9926 - val_accuracy: 0.6452\n",
            "Epoch 6/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.9541 - accuracy: 0.6677 - val_loss: 1.1411 - val_accuracy: 0.6383\n",
            "Epoch 7/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.8977 - accuracy: 0.6923 - val_loss: 1.0567 - val_accuracy: 0.6470\n",
            "Epoch 8/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.8416 - accuracy: 0.7105 - val_loss: 0.8467 - val_accuracy: 0.7139\n",
            "Epoch 9/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.7973 - accuracy: 0.7300 - val_loss: 0.8978 - val_accuracy: 0.7060\n",
            "Epoch 10/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.7592 - accuracy: 0.7422 - val_loss: 0.8245 - val_accuracy: 0.7254\n",
            "Epoch 11/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.7302 - accuracy: 0.7545 - val_loss: 0.8215 - val_accuracy: 0.7327\n",
            "Epoch 12/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6952 - accuracy: 0.7655 - val_loss: 0.7048 - val_accuracy: 0.7661\n",
            "Epoch 13/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6655 - accuracy: 0.7768 - val_loss: 0.8761 - val_accuracy: 0.7213\n",
            "Epoch 14/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6461 - accuracy: 0.7831 - val_loss: 0.6903 - val_accuracy: 0.7806\n",
            "Epoch 15/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6235 - accuracy: 0.7914 - val_loss: 0.8234 - val_accuracy: 0.7362\n",
            "Epoch 16/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6055 - accuracy: 0.7955 - val_loss: 0.7758 - val_accuracy: 0.7546\n",
            "Epoch 17/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5850 - accuracy: 0.8027 - val_loss: 1.3214 - val_accuracy: 0.6130\n",
            "Epoch 18/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5641 - accuracy: 0.8105 - val_loss: 0.5865 - val_accuracy: 0.8052\n",
            "Epoch 19/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5518 - accuracy: 0.8149 - val_loss: 0.7483 - val_accuracy: 0.7669\n",
            "Epoch 20/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5348 - accuracy: 0.8193 - val_loss: 0.5689 - val_accuracy: 0.8141\n",
            "Epoch 21/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5155 - accuracy: 0.8273 - val_loss: 0.5795 - val_accuracy: 0.8178\n",
            "Epoch 22/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5089 - accuracy: 0.8296 - val_loss: 0.5649 - val_accuracy: 0.8176\n",
            "Epoch 23/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4980 - accuracy: 0.8330 - val_loss: 0.6758 - val_accuracy: 0.7861\n",
            "Epoch 24/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4830 - accuracy: 0.8392 - val_loss: 0.5451 - val_accuracy: 0.8239\n",
            "Epoch 25/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4666 - accuracy: 0.8441 - val_loss: 0.6093 - val_accuracy: 0.8080\n",
            "Epoch 26/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4640 - accuracy: 0.8449 - val_loss: 0.6075 - val_accuracy: 0.8064\n",
            "Epoch 27/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4550 - accuracy: 0.8479 - val_loss: 0.6774 - val_accuracy: 0.7895\n",
            "Epoch 28/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4380 - accuracy: 0.8519 - val_loss: 0.6392 - val_accuracy: 0.7999\n",
            "Epoch 29/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4260 - accuracy: 0.8557 - val_loss: 0.5548 - val_accuracy: 0.8238\n",
            "Epoch 30/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4230 - accuracy: 0.8562 - val_loss: 0.7142 - val_accuracy: 0.7736\n",
            "Epoch 31/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4091 - accuracy: 0.8617 - val_loss: 0.5914 - val_accuracy: 0.8106\n",
            "Epoch 32/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4043 - accuracy: 0.8644 - val_loss: 0.5583 - val_accuracy: 0.8234\n",
            "Epoch 33/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3988 - accuracy: 0.8659 - val_loss: 0.5579 - val_accuracy: 0.8238\n",
            "Epoch 34/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3892 - accuracy: 0.8681 - val_loss: 0.5389 - val_accuracy: 0.8307\n",
            "Epoch 35/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3824 - accuracy: 0.8707 - val_loss: 0.6345 - val_accuracy: 0.8008\n",
            "Epoch 36/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3762 - accuracy: 0.8728 - val_loss: 0.6363 - val_accuracy: 0.8032\n",
            "Epoch 37/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3630 - accuracy: 0.8760 - val_loss: 0.6702 - val_accuracy: 0.7943\n",
            "Epoch 38/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3580 - accuracy: 0.8778 - val_loss: 0.6064 - val_accuracy: 0.8149\n",
            "Epoch 39/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3550 - accuracy: 0.8790 - val_loss: 0.6077 - val_accuracy: 0.8139\n",
            "Epoch 40/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3425 - accuracy: 0.8833 - val_loss: 0.6441 - val_accuracy: 0.8037\n",
            "Epoch 41/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3440 - accuracy: 0.8828 - val_loss: 0.5758 - val_accuracy: 0.8199\n",
            "Epoch 42/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3382 - accuracy: 0.8845 - val_loss: 0.5905 - val_accuracy: 0.8161\n",
            "Epoch 43/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3224 - accuracy: 0.8910 - val_loss: 0.6020 - val_accuracy: 0.8186\n",
            "Epoch 44/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3274 - accuracy: 0.8898 - val_loss: 0.5232 - val_accuracy: 0.8356\n",
            "Epoch 45/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3185 - accuracy: 0.8911 - val_loss: 0.6907 - val_accuracy: 0.7998\n",
            "Epoch 46/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3120 - accuracy: 0.8937 - val_loss: 0.6836 - val_accuracy: 0.7983\n",
            "Epoch 47/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3063 - accuracy: 0.8956 - val_loss: 0.6645 - val_accuracy: 0.8087\n",
            "Epoch 48/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3047 - accuracy: 0.8955 - val_loss: 0.5480 - val_accuracy: 0.8394\n",
            "Epoch 49/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2934 - accuracy: 0.8999 - val_loss: 0.6457 - val_accuracy: 0.8184\n",
            "Epoch 50/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2946 - accuracy: 0.9003 - val_loss: 0.5550 - val_accuracy: 0.8335\n",
            "Epoch 51/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2893 - accuracy: 0.9021 - val_loss: 0.6134 - val_accuracy: 0.8195\n",
            "Epoch 52/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2850 - accuracy: 0.9033 - val_loss: 0.6018 - val_accuracy: 0.8226\n",
            "Epoch 53/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2854 - accuracy: 0.9016 - val_loss: 0.7632 - val_accuracy: 0.7769\n",
            "Epoch 54/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2721 - accuracy: 0.9066 - val_loss: 0.8476 - val_accuracy: 0.7794\n",
            "Epoch 55/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2740 - accuracy: 0.9072 - val_loss: 0.5800 - val_accuracy: 0.8290\n",
            "Epoch 56/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2717 - accuracy: 0.9078 - val_loss: 0.6294 - val_accuracy: 0.8192\n",
            "Epoch 57/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2616 - accuracy: 0.9108 - val_loss: 0.5729 - val_accuracy: 0.8339\n",
            "Epoch 58/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2613 - accuracy: 0.9090 - val_loss: 0.5584 - val_accuracy: 0.8416\n",
            "Epoch 59/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2529 - accuracy: 0.9124 - val_loss: 0.5878 - val_accuracy: 0.8311\n",
            "Epoch 60/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2528 - accuracy: 0.9127 - val_loss: 0.7814 - val_accuracy: 0.7784\n",
            "Epoch 61/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2496 - accuracy: 0.9146 - val_loss: 0.5582 - val_accuracy: 0.8371\n",
            "Epoch 62/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2503 - accuracy: 0.9145 - val_loss: 0.5309 - val_accuracy: 0.8484\n",
            "Epoch 63/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2467 - accuracy: 0.9160 - val_loss: 0.5078 - val_accuracy: 0.8528\n",
            "Epoch 64/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2400 - accuracy: 0.9188 - val_loss: 0.5593 - val_accuracy: 0.8388\n",
            "Epoch 65/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2361 - accuracy: 0.9189 - val_loss: 0.5661 - val_accuracy: 0.8371\n",
            "Epoch 66/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2341 - accuracy: 0.9193 - val_loss: 0.8598 - val_accuracy: 0.7817\n",
            "Epoch 67/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2320 - accuracy: 0.9209 - val_loss: 0.5208 - val_accuracy: 0.8508\n",
            "Epoch 68/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2289 - accuracy: 0.9214 - val_loss: 0.5819 - val_accuracy: 0.8376\n",
            "Epoch 69/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2306 - accuracy: 0.9213 - val_loss: 0.5244 - val_accuracy: 0.8444\n",
            "Epoch 70/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2215 - accuracy: 0.9240 - val_loss: 0.5710 - val_accuracy: 0.8418\n",
            "Epoch 71/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2197 - accuracy: 0.9247 - val_loss: 0.5744 - val_accuracy: 0.8419\n",
            "Epoch 72/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2131 - accuracy: 0.9268 - val_loss: 0.5456 - val_accuracy: 0.8502\n",
            "Epoch 73/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2126 - accuracy: 0.9267 - val_loss: 0.5497 - val_accuracy: 0.8469\n",
            "Epoch 74/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2080 - accuracy: 0.9285 - val_loss: 0.5722 - val_accuracy: 0.8438\n",
            "Epoch 75/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2129 - accuracy: 0.9271 - val_loss: 0.5901 - val_accuracy: 0.8378\n",
            "Epoch 76/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2037 - accuracy: 0.9302 - val_loss: 0.6089 - val_accuracy: 0.8324\n",
            "Epoch 77/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1960 - accuracy: 0.9328 - val_loss: 0.6551 - val_accuracy: 0.8317\n",
            "Epoch 78/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2031 - accuracy: 0.9311 - val_loss: 0.6267 - val_accuracy: 0.8387\n",
            "Epoch 79/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1973 - accuracy: 0.9322 - val_loss: 0.6075 - val_accuracy: 0.8424\n",
            "Epoch 80/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1974 - accuracy: 0.9339 - val_loss: 0.6398 - val_accuracy: 0.8283\n",
            "Epoch 81/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1915 - accuracy: 0.9355 - val_loss: 0.5807 - val_accuracy: 0.8437\n",
            "Epoch 82/200\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.1942 - accuracy: 0.9341 - val_loss: 0.5543 - val_accuracy: 0.8461\n",
            "Epoch 83/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1880 - accuracy: 0.9356 - val_loss: 0.6241 - val_accuracy: 0.8380\n",
            "Epoch 84/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1897 - accuracy: 0.9350 - val_loss: 0.5653 - val_accuracy: 0.8495\n",
            "Epoch 85/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1845 - accuracy: 0.9368 - val_loss: 0.5762 - val_accuracy: 0.8457\n",
            "Epoch 86/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1825 - accuracy: 0.9373 - val_loss: 0.6121 - val_accuracy: 0.8384\n",
            "Epoch 87/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1841 - accuracy: 0.9365 - val_loss: 0.5789 - val_accuracy: 0.8480\n",
            "Epoch 88/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1776 - accuracy: 0.9382 - val_loss: 0.5615 - val_accuracy: 0.8543\n",
            "Epoch 89/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1759 - accuracy: 0.9402 - val_loss: 0.5835 - val_accuracy: 0.8466\n",
            "Epoch 90/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1778 - accuracy: 0.9397 - val_loss: 0.5619 - val_accuracy: 0.8547\n",
            "Epoch 91/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1733 - accuracy: 0.9407 - val_loss: 0.6687 - val_accuracy: 0.8286\n",
            "Epoch 92/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1732 - accuracy: 0.9401 - val_loss: 0.6203 - val_accuracy: 0.8340\n",
            "Epoch 93/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1704 - accuracy: 0.9427 - val_loss: 0.6159 - val_accuracy: 0.8406\n",
            "Epoch 94/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1677 - accuracy: 0.9418 - val_loss: 0.7747 - val_accuracy: 0.8043\n",
            "Epoch 95/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1653 - accuracy: 0.9435 - val_loss: 0.7498 - val_accuracy: 0.8091\n",
            "Epoch 96/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1659 - accuracy: 0.9432 - val_loss: 0.5950 - val_accuracy: 0.8483\n",
            "Epoch 97/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1624 - accuracy: 0.9438 - val_loss: 0.5779 - val_accuracy: 0.8514\n",
            "Epoch 98/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1639 - accuracy: 0.9446 - val_loss: 0.7318 - val_accuracy: 0.8125\n",
            "Epoch 99/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1641 - accuracy: 0.9448 - val_loss: 0.5896 - val_accuracy: 0.8461\n",
            "Epoch 100/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1600 - accuracy: 0.9458 - val_loss: 0.5816 - val_accuracy: 0.8484\n",
            "Epoch 101/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1581 - accuracy: 0.9466 - val_loss: 0.5807 - val_accuracy: 0.8542\n",
            "Epoch 102/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1598 - accuracy: 0.9461 - val_loss: 0.6549 - val_accuracy: 0.8336\n",
            "Epoch 103/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1554 - accuracy: 0.9465 - val_loss: 0.6071 - val_accuracy: 0.8456\n",
            "Epoch 104/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1514 - accuracy: 0.9480 - val_loss: 0.6197 - val_accuracy: 0.8437\n",
            "Epoch 105/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1489 - accuracy: 0.9494 - val_loss: 0.6274 - val_accuracy: 0.8393\n",
            "Epoch 106/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1530 - accuracy: 0.9477 - val_loss: 0.6310 - val_accuracy: 0.8351\n",
            "Epoch 107/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1511 - accuracy: 0.9498 - val_loss: 0.6099 - val_accuracy: 0.8466\n",
            "Epoch 108/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1514 - accuracy: 0.9492 - val_loss: 0.6352 - val_accuracy: 0.8430\n",
            "Epoch 109/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1471 - accuracy: 0.9503 - val_loss: 0.6133 - val_accuracy: 0.8487\n",
            "Epoch 110/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1417 - accuracy: 0.9525 - val_loss: 0.5916 - val_accuracy: 0.8529\n",
            "Epoch 111/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1442 - accuracy: 0.9505 - val_loss: 0.6956 - val_accuracy: 0.8306\n",
            "Epoch 112/200\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.1414 - accuracy: 0.9524 - val_loss: 0.6639 - val_accuracy: 0.8434\n",
            "Epoch 113/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1397 - accuracy: 0.9528 - val_loss: 0.6340 - val_accuracy: 0.8431\n",
            "Epoch 114/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1370 - accuracy: 0.9522 - val_loss: 0.6294 - val_accuracy: 0.8460\n",
            "Epoch 115/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1399 - accuracy: 0.9529 - val_loss: 0.6655 - val_accuracy: 0.8350\n",
            "Epoch 116/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1392 - accuracy: 0.9532 - val_loss: 0.6458 - val_accuracy: 0.8436\n",
            "Epoch 117/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1353 - accuracy: 0.9537 - val_loss: 0.6056 - val_accuracy: 0.8508\n",
            "Epoch 118/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1370 - accuracy: 0.9534 - val_loss: 0.6368 - val_accuracy: 0.8426\n",
            "Epoch 119/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1364 - accuracy: 0.9547 - val_loss: 0.6011 - val_accuracy: 0.8529\n",
            "Epoch 120/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1325 - accuracy: 0.9552 - val_loss: 0.6675 - val_accuracy: 0.8400\n",
            "Epoch 121/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1274 - accuracy: 0.9568 - val_loss: 0.6427 - val_accuracy: 0.8440\n",
            "Epoch 122/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1276 - accuracy: 0.9557 - val_loss: 0.6191 - val_accuracy: 0.8450\n",
            "Epoch 123/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1308 - accuracy: 0.9555 - val_loss: 0.6517 - val_accuracy: 0.8425\n",
            "Epoch 124/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1326 - accuracy: 0.9553 - val_loss: 0.6065 - val_accuracy: 0.8561\n",
            "Epoch 125/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1307 - accuracy: 0.9551 - val_loss: 0.6505 - val_accuracy: 0.8478\n",
            "Epoch 126/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1259 - accuracy: 0.9588 - val_loss: 0.6102 - val_accuracy: 0.8477\n",
            "Epoch 127/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1272 - accuracy: 0.9586 - val_loss: 0.6413 - val_accuracy: 0.8441\n",
            "Epoch 128/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1284 - accuracy: 0.9563 - val_loss: 0.6350 - val_accuracy: 0.8414\n",
            "Epoch 129/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1273 - accuracy: 0.9573 - val_loss: 0.6162 - val_accuracy: 0.8474\n",
            "Epoch 130/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1224 - accuracy: 0.9593 - val_loss: 0.6521 - val_accuracy: 0.8424\n",
            "Epoch 131/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1232 - accuracy: 0.9586 - val_loss: 0.6096 - val_accuracy: 0.8471\n",
            "Epoch 132/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1230 - accuracy: 0.9584 - val_loss: 0.6756 - val_accuracy: 0.8415\n",
            "Epoch 133/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1188 - accuracy: 0.9603 - val_loss: 0.6507 - val_accuracy: 0.8460\n",
            "Epoch 134/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1211 - accuracy: 0.9592 - val_loss: 0.6434 - val_accuracy: 0.8494\n",
            "Epoch 135/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1218 - accuracy: 0.9595 - val_loss: 0.6817 - val_accuracy: 0.8420\n",
            "Epoch 136/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1170 - accuracy: 0.9609 - val_loss: 0.6586 - val_accuracy: 0.8459\n",
            "Epoch 137/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1165 - accuracy: 0.9597 - val_loss: 0.6171 - val_accuracy: 0.8536\n",
            "Epoch 138/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1168 - accuracy: 0.9607 - val_loss: 0.6115 - val_accuracy: 0.8538\n",
            "Epoch 139/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1164 - accuracy: 0.9602 - val_loss: 0.6333 - val_accuracy: 0.8503\n",
            "Epoch 140/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1146 - accuracy: 0.9609 - val_loss: 0.6061 - val_accuracy: 0.8537\n",
            "Epoch 141/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1193 - accuracy: 0.9602 - val_loss: 0.6619 - val_accuracy: 0.8485\n",
            "Epoch 142/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1131 - accuracy: 0.9622 - val_loss: 0.6786 - val_accuracy: 0.8395\n",
            "Epoch 143/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1141 - accuracy: 0.9620 - val_loss: 0.6353 - val_accuracy: 0.8494\n",
            "Epoch 144/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1158 - accuracy: 0.9610 - val_loss: 0.6260 - val_accuracy: 0.8527\n",
            "Epoch 145/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1100 - accuracy: 0.9636 - val_loss: 0.6254 - val_accuracy: 0.8503\n",
            "Epoch 146/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1117 - accuracy: 0.9614 - val_loss: 0.6271 - val_accuracy: 0.8501\n",
            "Epoch 147/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1099 - accuracy: 0.9633 - val_loss: 0.6636 - val_accuracy: 0.8472\n",
            "Epoch 148/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.7262 - val_accuracy: 0.8317\n",
            "Epoch 149/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1067 - accuracy: 0.9641 - val_loss: 0.6146 - val_accuracy: 0.8558\n",
            "Epoch 150/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1063 - accuracy: 0.9651 - val_loss: 0.7737 - val_accuracy: 0.8260\n",
            "Epoch 151/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1098 - accuracy: 0.9642 - val_loss: 0.6287 - val_accuracy: 0.8508\n",
            "Epoch 152/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1098 - accuracy: 0.9637 - val_loss: 0.6387 - val_accuracy: 0.8528\n",
            "Epoch 153/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1086 - accuracy: 0.9631 - val_loss: 0.6224 - val_accuracy: 0.8521\n",
            "Epoch 154/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1053 - accuracy: 0.9650 - val_loss: 0.6460 - val_accuracy: 0.8495\n",
            "Epoch 155/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0992 - accuracy: 0.9663 - val_loss: 0.7291 - val_accuracy: 0.8329\n",
            "Epoch 156/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1046 - accuracy: 0.9640 - val_loss: 0.6263 - val_accuracy: 0.8476\n",
            "Epoch 157/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1059 - accuracy: 0.9643 - val_loss: 0.6197 - val_accuracy: 0.8510\n",
            "Epoch 158/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1017 - accuracy: 0.9655 - val_loss: 0.6523 - val_accuracy: 0.8488\n",
            "Epoch 159/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1069 - accuracy: 0.9643 - val_loss: 0.6824 - val_accuracy: 0.8481\n",
            "Epoch 160/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0966 - accuracy: 0.9663 - val_loss: 0.6614 - val_accuracy: 0.8504\n",
            "Epoch 161/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1016 - accuracy: 0.9658 - val_loss: 0.6783 - val_accuracy: 0.8408\n",
            "Epoch 162/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1021 - accuracy: 0.9647 - val_loss: 0.6552 - val_accuracy: 0.8486\n",
            "Epoch 163/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1047 - accuracy: 0.9658 - val_loss: 0.6937 - val_accuracy: 0.8394\n",
            "Epoch 164/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0955 - accuracy: 0.9675 - val_loss: 0.6502 - val_accuracy: 0.8549\n",
            "Epoch 165/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1001 - accuracy: 0.9663 - val_loss: 0.6499 - val_accuracy: 0.8538\n",
            "Epoch 166/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0974 - accuracy: 0.9676 - val_loss: 0.6453 - val_accuracy: 0.8535\n",
            "Epoch 167/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0957 - accuracy: 0.9678 - val_loss: 0.6936 - val_accuracy: 0.8465\n",
            "Epoch 168/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1006 - accuracy: 0.9662 - val_loss: 0.7053 - val_accuracy: 0.8451\n",
            "Epoch 169/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0985 - accuracy: 0.9675 - val_loss: 0.6522 - val_accuracy: 0.8525\n",
            "Epoch 170/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0964 - accuracy: 0.9681 - val_loss: 0.7712 - val_accuracy: 0.8317\n",
            "Epoch 171/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0991 - accuracy: 0.9669 - val_loss: 0.6203 - val_accuracy: 0.8547\n",
            "Epoch 172/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0935 - accuracy: 0.9682 - val_loss: 0.8117 - val_accuracy: 0.8269\n",
            "Epoch 173/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0976 - accuracy: 0.9670 - val_loss: 0.6188 - val_accuracy: 0.8536\n",
            "Epoch 174/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0944 - accuracy: 0.9683 - val_loss: 0.7065 - val_accuracy: 0.8389\n",
            "Epoch 175/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0937 - accuracy: 0.9678 - val_loss: 0.6252 - val_accuracy: 0.8524\n",
            "Epoch 176/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0937 - accuracy: 0.9688 - val_loss: 0.6832 - val_accuracy: 0.8529\n",
            "Epoch 177/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0944 - accuracy: 0.9690 - val_loss: 0.6594 - val_accuracy: 0.8481\n",
            "Epoch 178/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0884 - accuracy: 0.9697 - val_loss: 0.6877 - val_accuracy: 0.8503\n",
            "Epoch 179/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0896 - accuracy: 0.9698 - val_loss: 0.7295 - val_accuracy: 0.8380\n",
            "Epoch 180/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0900 - accuracy: 0.9701 - val_loss: 0.7047 - val_accuracy: 0.8434\n",
            "Epoch 181/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0940 - accuracy: 0.9682 - val_loss: 0.6805 - val_accuracy: 0.8503\n",
            "Epoch 182/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0880 - accuracy: 0.9702 - val_loss: 0.7532 - val_accuracy: 0.8307\n",
            "Epoch 183/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0894 - accuracy: 0.9706 - val_loss: 0.6138 - val_accuracy: 0.8658\n",
            "Epoch 184/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0868 - accuracy: 0.9698 - val_loss: 0.6441 - val_accuracy: 0.8536\n",
            "Epoch 185/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0854 - accuracy: 0.9718 - val_loss: 0.6954 - val_accuracy: 0.8523\n",
            "Epoch 186/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0923 - accuracy: 0.9693 - val_loss: 0.6347 - val_accuracy: 0.8571\n",
            "Epoch 187/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0892 - accuracy: 0.9702 - val_loss: 0.6940 - val_accuracy: 0.8490\n",
            "Epoch 188/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0886 - accuracy: 0.9707 - val_loss: 0.7390 - val_accuracy: 0.8330\n",
            "Epoch 189/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0840 - accuracy: 0.9712 - val_loss: 0.6367 - val_accuracy: 0.8638\n",
            "Epoch 190/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0883 - accuracy: 0.9707 - val_loss: 0.7200 - val_accuracy: 0.8479\n",
            "Epoch 191/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0908 - accuracy: 0.9687 - val_loss: 0.7162 - val_accuracy: 0.8482\n",
            "Epoch 192/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0854 - accuracy: 0.9713 - val_loss: 0.6611 - val_accuracy: 0.8534\n",
            "Epoch 193/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.7007 - val_accuracy: 0.8502\n",
            "Epoch 194/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0851 - accuracy: 0.9718 - val_loss: 0.7085 - val_accuracy: 0.8519\n",
            "Epoch 195/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0874 - accuracy: 0.9705 - val_loss: 0.7169 - val_accuracy: 0.8485\n",
            "Epoch 196/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0884 - accuracy: 0.9702 - val_loss: 0.6538 - val_accuracy: 0.8537\n",
            "Epoch 197/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0846 - accuracy: 0.9720 - val_loss: 0.7044 - val_accuracy: 0.8521\n",
            "Epoch 198/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0839 - accuracy: 0.9713 - val_loss: 0.6589 - val_accuracy: 0.8560\n",
            "Epoch 199/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0813 - accuracy: 0.9728 - val_loss: 0.6975 - val_accuracy: 0.8480\n",
            "Epoch 200/200\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0841 - accuracy: 0.9725 - val_loss: 0.6560 - val_accuracy: 0.8524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}